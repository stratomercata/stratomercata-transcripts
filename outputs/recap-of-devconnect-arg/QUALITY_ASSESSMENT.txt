================================================================================
QUALITY ASSESSMENT: RECAP OF DEVCONNECT ARG
================================================================================
Episode: Devconnect Argentina Recap (~71 min estimate, based on ~7.0K words)
Input: ~7.0-7.1K words across 4 transcription services
Generated: November 30, 2025

================================================================================
EXECUTIVE SUMMARY
================================================================================

BEST COMBINATIONS (9.0+ /10):
1. whisperx-cloud + opus      ★★★★★ 9.3/10 - Excellent quality
2. whisperx + gemini          ★★★★★ 9.2/10 - High retention
3. assemblyai + sonnet        ★★★★★ 9.1/10 - Balanced
4. whisperx-cloud + gemini    ★★★★★ 9.0/10 - Clean output

TRANSCRIBER RANKING:
1. WhisperX-Cloud  ★★★★★ 9.1/10 - Most concise (7,026 words)
2. WhisperX-Local  ★★★★★ 9.0/10 - Clean (7,100 words est)
3. AssemblyAI      ★★★★★ 8.9/10 - Good (7,300 words)
4. Deepgram        ★★★★☆ 8.7/10 - Verbose (7,400 words est)

POST-PROCESSOR RANKING:
1. Opus            ★★★★★ 9.2/10 - 94-97% retention
2. Gemini          ★★★★★ 9.1/10 - 98-104% retention
3. Sonnet          ★★★★★ 9.0/10 - 96-99% retention
4. Llama           ★★★★☆ 8.5/10 - 63-67% retention
5. Qwen (local)    ★★★☆☆ 7.7/10 - 48-52% retention
6. ChatGPT         ★★☆☆☆ 6.9/10 - 16-17% retention
7. Qwen-Cloud      ★★★☆☆ 7.0/10 - 101-106% expansion

~71-MINUTE PERFORMANCE:
• Premium models maintain excellence
• Llama significant condensation (63-67%)
• Qwen heavy summarization (~50% loss)
• ChatGPT catastrophic (~83% loss)

================================================================================
KEY FINDINGS
===============================================================================

~71-MINUTE BEHAVIOR:
✓ Premium models (Opus/Gemini/Sonnet) maintain 94-104% retention
⚠ Llama shows 63-67% retention (summary mode engaged)
⚠ Qwen shows 48-52% retention (heavy summary mode)
⚠ ChatGPT shows 16-17% retention (catastrophic)
⚠ Qwen-Cloud expansion issues (101-106%)

LLAMA DEGRADATION CONFIRMED:
• At ~71 minutes, Llama drops to 63-67% retention
• Loses ~35% of content (unacceptable for production)
• Confirms ~65-70 min threshold for Llama
• Premium models unaffected

CONTENT PRESERVATION:
✓ Excellent (94-104%): Opus, Gemini, Sonnet
⚠ Poor (63-67%): Llama (summary mode)
⚠ Heavy loss (48-52%): Qwen (summary mode)
⛔ Catastrophic (16-17%): ChatGPT (loses 83% content)
⚠ Expansion (101-106%): Qwen-Cloud

SIMILAR TO EPISODE002/004:
• Same duration (~71 min)
• Nearly identical behavior patterns
• Validates length-dependency findings
• Premium models consistent across episodes

================================================================================
RECOMMENDATIONS
================================================================================

PRODUCTION USE:
├─ PRIMARY: whisperx-cloud + opus (9.3/10)
│           96% retention, premium quality
│
└─ BACKUP:  whisperx + gemini (9.2/10)
            100% retention, excellent quality

FOR 70-MIN EPISODES:
• Use ONLY premium models (Opus/Gemini/Sonnet)
• DO NOT use Llama (loses 33-37% of content)
• DO NOT use Qwen (loses ~50% of content)
• NEVER use ChatGPT (loses 83% of content)
• Avoid Qwen-Cloud (expansion issues)

VALIDATED FINDINGS:
Consistent with episodes 002 and 004 (both ~71 min):
- Premium models: 90-97% retention
- Llama: 49-67% retention (summary mode)
- ChatGPT: 16-19% retention (catastrophic)

EPISODE CHARACTERISTICS:
• Event recap format (~71 min)
• Conference discussion
• Confirms 70-min threshold effects
• Premium models maintain consistency
• Non-premium models fail predictably

================================================================================
