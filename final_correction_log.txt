
=== alex-van-de-sande-interview_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/alex-van-de-sande-interview_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 86001 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   Large transcript detected (86001 chars, ~22292 tokens)
   Splitting into chunks for processing...
   Processing 6 chunks...
   Processing chunk 1/6... ✓
   Processing chunk 2/6... ✓
   Processing chunk 3/6... ✓
   Processing chunk 4/6... ✓
   Processing chunk 5/6... ✓
   Processing chunk 6/6... ✓
   ✓ Processing complete

4. Saved corrected transcript to: outputs/alex-van-de-sande-interview_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/alex-van-de-sande-interview_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== are_corporate_chains_back_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/are_corporate_chains_back_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 46184 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   ✓ Processing complete

4. Saved corrected transcript to: outputs/are_corporate_chains_back_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/are_corporate_chains_back_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== episode001_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/episode001_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 112126 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   Large transcript detected (112126 chars, ~28823 tokens)
   Splitting into chunks for processing...
   Processing 8 chunks...
   Processing chunk 1/8... ✓
   Processing chunk 2/8... ✓
   Processing chunk 3/8... ✓
   Processing chunk 4/8... ✓
   Processing chunk 5/8... ✓
   Processing chunk 6/8... ✓
   Processing chunk 7/8... ✓
   Processing chunk 8/8... ✓
   ✓ Processing complete

4. Saved corrected transcript to: outputs/episode001_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/episode001_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== episode002_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/episode002_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 69884 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   Large transcript detected (69884 chars, ~18263 tokens)
   Splitting into chunks for processing...
   Processing 5 chunks...
   Processing chunk 1/5... ✓
   Processing chunk 2/5... ✓
   Processing chunk 3/5... ✓
   Processing chunk 4/5... ✓
   Processing chunk 5/5... ✓
   ✓ Processing complete

4. Saved corrected transcript to: outputs/episode002_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/episode002_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== episode003-bob-summerwill_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/episode003-bob-summerwill_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 73720 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   Large transcript detected (73720 chars, ~19222 tokens)
   Splitting into chunks for processing...
   Processing 5 chunks...
   Processing chunk 1/5... ✓
   Processing chunk 2/5... ✓
   Processing chunk 3/5... ✓
   Processing chunk 4/5... ✓
   Processing chunk 5/5... ✓
   ✓ Processing complete

4. Saved corrected transcript to: outputs/episode003-bob-summerwill_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/episode003-bob-summerwill_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== episode004-taylor-gerring_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/episode004-taylor-gerring_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 62383 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   Large transcript detected (62383 chars, ~16388 tokens)
   Splitting into chunks for processing...
   Processing 5 chunks...
   Processing chunk 1/5... ✓
   Processing chunk 2/5... ✓
   Processing chunk 3/5... ✓
   Processing chunk 4/5... ✓
   Processing chunk 5/5... ✓
   ✓ Processing complete

4. Saved corrected transcript to: outputs/episode004-taylor-gerring_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/episode004-taylor-gerring_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== episode005-anthony-d-onofrio_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/episode005-anthony-d-onofrio_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 86139 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   Large transcript detected (86139 chars, ~22327 tokens)
   Splitting into chunks for processing...
   Processing 6 chunks...
   Processing chunk 1/6... ✓
   Processing chunk 2/6... ✓
   Processing chunk 3/6... ✓
   Processing chunk 4/6... ✓
   Processing chunk 5/6... ✓
   Processing chunk 6/6... ✓
   ✓ Processing complete

4. Saved corrected transcript to: outputs/episode005-anthony-d-onofrio_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/episode005-anthony-d-onofrio_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== fabian-vogelsteller-interview_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/fabian-vogelsteller-interview_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 95642 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   Large transcript detected (95642 chars, ~24702 tokens)
   Splitting into chunks for processing...
   Processing 7 chunks...
   Processing chunk 1/7... ✓
   Processing chunk 2/7... ✓
   Processing chunk 3/7... ✓
   Processing chunk 4/7... ✓
   Processing chunk 5/7... ✓
   Processing chunk 6/7... ✓
   Processing chunk 7/7... ✓
   ✓ Processing complete

4. Saved corrected transcript to: outputs/fabian-vogelsteller-interview_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/fabian-vogelsteller-interview_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== institutions_want_tokens_how_is_ethereum_keeping_up_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/institutions_want_tokens_how_is_ethereum_keeping_up_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 50988 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   ✓ Processing complete

4. Saved corrected transcript to: outputs/institutions_want_tokens_how_is_ethereum_keeping_up_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/institutions_want_tokens_how_is_ethereum_keeping_up_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== is_better_web3_ux_the_key_to_mainstream_adoption_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/is_better_web3_ux_the_key_to_mainstream_adoption_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 35314 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   ✓ Processing complete

4. Saved corrected transcript to: outputs/is_better_web3_ux_the_key_to_mainstream_adoption_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/is_better_web3_ux_the_key_to_mainstream_adoption_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== launch-of-mercata-v2-app-walkthrough_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/launch-of-mercata-v2-app-walkthrough_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 29502 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   ✓ Processing complete

4. Saved corrected transcript to: outputs/launch-of-mercata-v2-app-walkthrough_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/launch-of-mercata-v2-app-walkthrough_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== mercata_v2_contest_winners_announced_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/mercata_v2_contest_winners_announced_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 28346 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   ✓ Processing complete

4. Saved corrected transcript to: outputs/mercata_v2_contest_winners_announced_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/mercata_v2_contest_winners_announced_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== mercata_v2_context_kickoff_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/mercata_v2_context_kickoff_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 11015 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   ✓ Processing complete

4. Saved corrected transcript to: outputs/mercata_v2_context_kickoff_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/mercata_v2_context_kickoff_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== strato-mercata-show-2025.10.08_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/strato-mercata-show-2025.10.08_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 39075 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   ✓ Processing complete

4. Saved corrected transcript to: outputs/strato-mercata-show-2025.10.08_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/strato-mercata-show-2025.10.08_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================

=== william-entriken-interview_transcript_with_speakers.txt ===
============================================================
Transcript Post-Processor
============================================================
Input: outputs/william-entriken-interview_transcript_with_speakers.txt
Provider: openai
Model: chatgpt-4o-latest

1. Loading transcript...
   Loaded 64387 characters

2. Building context from glossary...
   Context built: 1169 characters

3. Processing with openai...
   Large transcript detected (64387 chars, ~16889 tokens)
   Splitting into chunks for processing...
   Processing 5 chunks...
   Processing chunk 1/5... ✓
   Processing chunk 2/5... ✓
   Processing chunk 3/5... ✓
   Processing chunk 4/5... ✓
   Processing chunk 5/5... ✓
   ✓ Processing complete

4. Saved corrected transcript to: outputs/william-entriken-interview_transcript_with_speakers_corrected.txt
   Also saved markdown to: outputs/william-entriken-interview_transcript_with_speakers_corrected.md

============================================================
✓ Post-processing complete!
============================================================
